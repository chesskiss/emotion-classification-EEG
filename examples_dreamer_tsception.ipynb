{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Train a Tsception Model on the DREAMER Dataset\n\nIn this tutorial, we'll showcase how you can use TorchEEG to train a Tsception model on the DREAMER dataset for the task of emotion classification. Let's go through the process step-by-step, covering everything from dataset preparation to model evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Initialize the Dataset\n\nFirst off, we'll use the DREAMER dataset provided by TorchEEG. Each EEG sample in this dataset spans 1 second and contains 128 data points. For each trial, the baseline signal lasts 61 seconds. \nDuring offline preprocessing, we perform several steps:\n- Divide each electrode's EEG signal into 4 frequency sub-bands\n- Compute the differential entropy of each sub-band as a feature\n- Eliminate the baseline from the signal\n- Map the preprocessed signals onto a 2D grid\nFor online processing, we convert the EEG signals into PyTorch Tensors to make them compatible with neural network inputs.\nLet's see how to accomplish these steps in code.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torcheeg.datasets import DREAMERDataset\nfrom torcheeg import transforms\n\ndataset = DREAMERDataset(io_path='./examples_dreamer_tsception/dreamer',\n                         mat_path='./DREAMER.mat',\n                         offline_transform=transforms.Compose([\n                             transforms.BaselineRemoval(),\n                             transforms.MeanStdNormalize(),\n                             transforms.To2d()\n                         ]),\n                         online_transform=transforms.ToTensor(),\n                         label_transform=transforms.Compose([\n                             transforms.Select('valence'),\n                             transforms.Binary(3.0)\n                         ]),\n                         chunk_size=128,\n                         baseline_chunk_size=128,\n                         num_baseline=61,\n                         num_worker=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Divide the Training and Test Samples in the Dataset\n\nNext, let's partition our dataset into training and test sets using 5-fold cross-validation. We group the data based on their trial index, where each trial contributes 4 folds to the training set and 1 fold to the test set. These grouped samples are then combined to form the final training and test sets.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torcheeg.model_selection import KFoldGroupbyTrial\n\nk_fold = KFoldGroupbyTrial(n_splits=5,\n                           split_path=f'./examples_dreamer_tsception/split')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Define the Model and Initiate Training\n\nHaving prepared and divided our dataset, we can now move on to model building and training. In each iteration of the cross-validation loop, we'll initialize the Tsception model and set its hyperparameters.\nHere, each EEG sample contains 128 data points across 14 electrodes. We'll train this model for 50 epochs using TorchEEG's `ClassifierTrainer`.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\nfrom torcheeg.models import TSCeption\n\nfrom torcheeg.trainers import ClassifierTrainer\n\nimport pytorch_lightning as pl\n\nfor i, (train_dataset, val_dataset) in enumerate(k_fold.split(dataset)):\n    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n\n    model = TSCeption(num_electrodes=14,\n                      num_classes=2,\n                      num_T=15,\n                      num_S=15,\n                      in_channels=1,\n                      hid_channels=32,\n                      sampling_rate=128,\n                      dropout=0.5)\n\n    trainer = ClassifierTrainer(model=model,\n                                num_classes=2,\n                                lr=1e-4,\n                                weight_decay=1e-4,\n                                accelerator=\"gpu\")\n    trainer.fit(train_loader,\n                val_loader,\n                max_epochs=50,\n                default_root_dir=f'./examples_dreamer_tsception/model/{i}',\n                callbacks=[pl.callbacks.ModelCheckpoint(save_last=True)],\n                enable_progress_bar=True,\n                enable_model_summary=True,\n                limit_val_batches=0.0)\n    score = trainer.test(val_loader,\n                         enable_progress_bar=True,\n                         enable_model_summary=True)[0]\n    print(f'Fold {i} test accuracy: {score[\"test_accuracy\"]:.4f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}